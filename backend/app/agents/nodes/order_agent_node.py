"""
Order Agent Node - Handles purchasing and cart operations
"""
from typing import List, Dict
from langchain_openai import ChatOpenAI
from langchain_core.messages import SystemMessage, AIMessage, ToolMessage
from langchain_core.tools import BaseTool
from langchain_core.runnables import RunnableConfig
import traceback
from app.agents.interceptors import UserContext
from app.agents.state import AgentState
from app.agents.mcp_manager import mcp_manager
from app.core.config import settings


class OrderAgentNode:
    """Order specialist agent"""

    SYSTEM_PROMPT = """You are an Order Assistant for an e-commerce cosmetics store.

**YOUR GOAL:**
Help users add products to their cart and manage orders.

**CRITICAL RULE: USE SHARED CONTEXT**
The user might say "buy the first one" or "add CeraVe to cart".
You MUST look at the **SHARED CONTEXT** (provided below) to find the correct `product_id`.

1. **IF Context has products:**
   - Map user's request (e.g., "product #1") to the ID in the context list.
   - Call `add_to_cart(product_id=...)`.
   - Confirm success to the user.

2. **IF Context is empty or unclear:**
   - Ask the user to search for the product first (route back to product agent indirectly by asking "Which product do you want to find?").

**Tools available:**
- `add_to_cart`: Use this to add items.
- `get_cart`: Use this to show current cart.

**Response Style:**
Be helpful, confirm the exact product name and price added.
"""

    def __init__(self):
        self.llm = ChatOpenAI(
            model="gpt-4o-mini",
            api_key=settings.OPENAI_API_KEY,
            temperature=0.3
        )
        self.tools: List[BaseTool] = []
        self.agent = None
        self._initialized = False
        print("‚úÖ Order agent node initialized")

    async def initialize_tools(self):
        """Load tools from MCP (Agent: order)"""
        if self._initialized:
            return

        print("üîÑ Loading order agent tools...")
        try:
            # üëá QUAN TR·ªåNG: Load tools c·ªßa 'order' agent
            self.tools = await mcp_manager.get_tools_for_agent("order")
            if self.tools:
                self.agent = self.llm.bind_tools(self.tools)
                self.tool_map = {tool.name: tool for tool in self.tools}
            else:
                self.agent = self.llm
                self.tool_map = {}
        except Exception as e:
            print(f"‚ùå Error loading order tools: {e}")
            self.agent = self.llm
            self.tool_map = {}

        self._initialized = True

    async def __call__(self, state: AgentState) -> dict:
        await self.initialize_tools()
        print(f"\n{'='*80}\nüõí ORDER AGENT\n{'='*80}")

        # 1. L·∫•y Shared Context ƒë·ªÉ Agent "nh√¨n th·∫•y" s·∫£n ph·∫©m
        shared_context = state.get("shared_context", {})
        found_products = shared_context.get("found_products", [])

        # Format context th√†nh chu·ªói ƒë·ªÉ nh√©t v√†o Prompt
        context_str = "NO PRODUCTS FOUND IN HISTORY."
        if found_products:
            # L·∫•y data th√¥ (List ho·∫∑c Dict)
            if isinstance(found_products, dict) and "products" in found_products:
                products_list = found_products["products"]
            elif isinstance(found_products, list):
                products_list = found_products
            else:
                products_list = []

            # T·∫°o text t√≥m t·∫Øt
            items_desc = []
            for idx, p in enumerate(products_list):
                # Handle c·∫£ tr∆∞·ªùng h·ª£p p l√† object ho·∫∑c string (d√π hi·∫øm)
                if isinstance(p, dict):
                    name = p.get("name", "Unknown")
                    pid = p.get("id", "NoID")
                    price = p.get("price", 0)
                    items_desc.append(
                        f"#{idx+1}: {name} (ID: {pid}) - {price}")

            if items_desc:
                context_str = "\n".join(items_desc)

        # 2. Inject Context v√†o System Prompt
        dynamic_prompt = f"{self.SYSTEM_PROMPT}\n\n=== CURRENT SHARED CONTEXT (RECENTLY FOUND PRODUCTS) ===\n{context_str}\n========================================================"

        messages = [SystemMessage(content=dynamic_prompt)]
        messages.extend(state["messages"][-10:])  # L·∫•y context g·∫ßn nh·∫•t

        generated_messages = []

        # Loop th·ª±c thi
        max_iterations = 5
        iteration = 0

        while iteration < max_iterations:
            iteration += 1
            print(f"   üìç Iteration {iteration}")

            response = await self.agent.ainvoke(messages)
            generated_messages.append(response)
            messages.append(response)

            if not response.tool_calls:
                return {
                    "messages": generated_messages,
                    "next_node": "quality_check"  # Chuy·ªÉn sang Quality Check ƒë·ªÉ format
                }

            print(f"   üîß Calling {len(response.tool_calls)} tool(s)")

            for tool_call in response.tool_calls:
                tool_name = tool_call["name"]

                # --- Logic Interceptor th·ªß c√¥ng (n·∫øu kh√¥ng d√πng th∆∞ vi·ªán) ---
                # Nh∆∞ng b·∫°n ƒë√£ c√≥ Interceptor x·ªãn ·ªü level MCPManager r·ªìi n√™n c·ª© g·ªçi tool b√¨nh th∆∞·ªùng
                # Tr·ª´ khi b·∫°n mu·ªën log debug

                tool_args = tool_call["args"]
                tool_id = tool_call["id"]
                tool = self.tool_map.get(tool_name)

                result_content = ""

                # --- LOGIC G·ªåI TOOL ---
                if tool:
                    try:
                        # ‚úÖ TH·ª∞C HI·ªÜN "MANUAL INTERCEPTOR" T·∫†I ƒê√ÇY

                        # 1. L·∫•y token t·ª´ State
                        user_token = state.get("auth_token", "")

                        # 2. T·∫°o b·∫£n sao ƒë·ªÉ th·ª±c thi (EXECUTION ARGS)
                        # ƒê√¢y ch√≠nh l√† vi·ªác m√† Interceptor l√†m ng·∫ßm, gi·ªù m√¨nh l√†m c√¥ng khai
                        execution_args = tool_args.copy()

                        # 3. Nh√©t token v√†o b·∫£n sao
                        if user_token:
                            execution_args["token"] = user_token
                            print("   üîê Auth token injected into request")

                        # 4. Log debug (Nh·ªõ che token l·∫°i ƒë·ªÉ kh√¥ng l·ªô log server)
                        log_args = execution_args.copy()
                        if "token" in log_args:
                            log_args["token"] = "***HIDDEN***"
                        print(
                            f"   üëâ DEBUG CALL: {tool_name} | Args: {log_args}")

                        # 5. G·ªçi tool b·∫±ng B·∫¢N SAO (C√≥ token)
                        # MCP Server s·∫Ω nh·∫≠n ƒë∆∞·ª£c args c√≥ token v√† x·ª≠ l√Ω Header
                        result_content = await tool.ainvoke(execution_args)

                        # Order Agent th∆∞·ªùng thay ƒë·ªïi d·ªØ li·ªáu, √≠t khi c·∫ßn update shared_context
                        # Tr·ª´ khi get_cart tr·∫£ v·ªÅ cart m·ªõi, ta c√≥ th·ªÉ l∆∞u cart v√†o context n·∫øu mu·ªën.

                    except Exception as e:
                        print(f"‚ùå TOOL ERROR: {e}")
                        traceback.print_exc()
                        result_content = f"Error: {str(e)}"
                else:
                    result_content = f"Error: Tool {tool_name} not found"

                tool_msg = ToolMessage(content=str(
                    result_content), tool_call_id=tool_id)
                generated_messages.append(tool_msg)
                messages.append(tool_msg)

        return {
            "messages": [AIMessage(content="I'm having trouble processing your order.")],
            "next_node": "quality_check"
        }
